{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: Building a GNN-Based Recommender System\n",
    "\n",
    "**Course:** Recommender Systems\n",
    "\n",
    "**Estimated Time:** 4 Hours\n",
    "\n",
    "**Topic:** Link Prediction for Music Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Project Goal\n",
    "\n",
    "The objective of this project is to build a recommender system that suggests new music artists to users. You will model the user-artist relationship as a **bipartite graph** and frame the recommendation task as a **link prediction problem**. You will implement a Graph Neural Network (GNN) to learn embeddings for users and artists, which will then be used to predict potential future interactions (i.e., which artists a user might like)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core Technologies\n",
    "\n",
    "You will use the following key libraries:\n",
    "\n",
    "* **pandas:** For data loading and initial manipulation.\n",
    "\n",
    "* **NetworkX:** To construct the initial user-artist graph.\n",
    "\n",
    "* **PyTorch & PyTorch Geometric (PyG):** For defining the GNN model, preparing the data, and training.\n",
    "\n",
    "* **scikit-learn:** For evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Dataset: Last.fm User-Artist Interactions\n",
    "\n",
    "We will use a dataset from the music streaming service **Last.fm**. It contains a list of users, the artists they have listened to, and the number of times they've played songs by that artist (a \"weight\"). This represents a rich set of implicit feedback.\n",
    "\n",
    "You can download the dataset here: [Last.fm Asia Social Network Dataset](https://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip)\n",
    "\n",
    "The key file you'll need is `user_artists.dat`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Step-by-Step Implementation Guide\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1: Environment Setup & Data Loading (Est. 20 mins)**\n",
    "\n",
    "Open the PowerShell Prompt as admin (in Windows) or the Terminal (in Mac and Linux), and strat by creating a conda environment:\n",
    "\n",
    "`conda create --name rec_gnn python=3.9`\n",
    "\n",
    "Install the demanded libraries:\n",
    "\n",
    "`pip install torch torch-geometric pandas networkx scikit-learn`\n",
    "\n",
    "Finally choose the kernel `rec_gnn` on VsCode to execute your code.\n",
    "\n",
    "**Load Data:** Use the `pandas` library to load the `user_artists.dat` file.\n",
    "  * Use the function `pd.read_csv()`, specifying the file path and setting the separator to `sep='\\t'`.\n",
    "  * Assign the column names: `['userID', 'artistID', 'listen_count']`.\n",
    "\n",
    "**Explore:** Print the head of the DataFrame and the number of unique users and artists to understand the data's scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports for the project\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Your code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"user_artists.dat\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"weight\": \"listen_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>listen_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>13883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>11690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>11351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>6152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>4147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  listen_count\n",
       "0       2        51         13883\n",
       "1       2        52         11690\n",
       "2       2        53         11351\n",
       "3       2        54         10300\n",
       "4       2        55          8983\n",
       "5       2        56          6152\n",
       "6       2        57          5955\n",
       "7       2        58          4616\n",
       "8       2        59          4337\n",
       "9       2        60          4147"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2: Building the Bipartite Graph with NetworkX (Est. 30 mins)**\n",
    "\n",
    "Now, convert the DataFrame of interactions into a single, undirected bipartite graph. A bipartite graph has two distinct sets of nodes, and edges only connect nodes from different sets (in our case, users to artists).\n",
    "\n",
    "1.  **Instantiate a Graph:** Create an empty graph object using `G = nx.Graph()`.\n",
    "2.  **Add Nodes with Attributes:** Iterate through the unique users and artists. For each one, you must add it to the graph with a special attribute to identify its type.\n",
    "    * For users, use `G.add_node(user_id, bipartite=0)`.\n",
    "    * For artists, use `G.add_node(artist_id, bipartite=1)`.\n",
    "3.  **Add Edges:** Iterate through each row of your DataFrame. For each row, create a connection between the user and the artist using `G.add_edge(row['userID'], row['artistID'])`. We will ignore the `listen_count` for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in df[\"userID\"].unique():\n",
    "    G.add_node(user_id, bipartite=0)\n",
    "\n",
    "for artist_id in df[\"artistID\"].unique():\n",
    "    G.add_node(artist_id, bipartite=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples(index=False):\n",
    "    G.add_edge(int(row.userID), int(row.artistID))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3: Preparing the Data with PyTorch Geometric (Est. 40 mins)**\n",
    "\n",
    "Next, you'll convert the NetworkX graph into a format that PyTorch Geometric can use. This involves creating a single `Data` object and then splitting its edges for training, validation, and testing.\n",
    "\n",
    "1.  **Map Node IDs:** Create a dictionary that maps every original `userID` and `artistID` to a unique integer from 0 to `num_nodes - 1`. This is required for the embedding layer.\n",
    "2.  **Create PyG Data Object:** Construct a `torch_geometric.data.Data` object. This will hold all the information about our graph.\n",
    "    * **Node Features (`x`):** We don't have initial features, so we'll use learnable embeddings instead. Create a tensor of node indices that the model will use to look up these embeddings. Use `torch.arange(num_nodes, dtype=torch.long)`.\n",
    "    * **Edge Index (`edge_index`):** Convert the list of graph edges into a tensor of shape `[2, num_edges]` where each column is an edge. Set its `dtype` to `torch.long`.\n",
    "3.  **Split Edges:** Use the modern `torch_geometric.transforms.RandomLinkSplit` transform to partition the edges. This is the standard method for link prediction tasks.\n",
    "    * Instantiate the transform: `transform = T.RandomLinkSplit(...)`.\n",
    "    * Inside the transform, set key parameters:\n",
    "        * `num_val=0.1` and `num_test=0.1` to hold out 10% of edges for validation and 10% for testing.\n",
    "        * `is_undirected=True` because our graph is undirected.\n",
    "        * `add_negative_train_samples=False` because we will perform negative sampling inside the training loop.\n",
    "        * `split_labels=True` to create the necessary `pos_edge_label_index` attributes.\n",
    "    * Apply it to your `data` object to get three new objects: `train_data, val_data, test_data = transform(data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df['userID'].unique()\n",
    "artist_id= df['artistID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id=list(user_id)+list (artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19524"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping = {original_id: new_id for new_id, original_id in enumerate(unique_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17644"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(len(id_mapping), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = df[[\"userID\",\"artistID\"]].copy()\n",
    "df_map[\"userID\"]= df_map[\"userID\"].map(id_mapping)\n",
    "df_map[\"artistID\"] = df_map[\"artistID\"].map(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5012</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5012</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5012</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5012</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5012</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5012</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5012</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5012</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5012</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5012</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID\n",
       "0    5012      1892\n",
       "1    5012      1893\n",
       "2    5012      1894\n",
       "3    5012      1895\n",
       "4    5012      1896\n",
       "5    5012      1897\n",
       "6    5012      1898\n",
       "7    5012      1899\n",
       "8    5012      1900\n",
       "9    5012      1901"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(\n",
    "    df_map[['userID', 'artistID']].values.T,  # transpose pour avoir [2, num_edges]\n",
    "    dtype=torch.long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5012,  5012,  5012,  ...,  3929,  3929,  3929],\n",
       "        [ 1892,  1893,  1894,  ..., 19521, 19522, 19523]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,                 \n",
    "    num_test=0.1,               \n",
    "    is_undirected=True,  \n",
    "    add_negative_train_samples=False,\n",
    "    split_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4: Implementing the GNN Model (Est. 60 mins)**\n",
    "\n",
    "Define your GNN using PyTorch and PyG. The model will learn dense vector representations (embeddings) for all users and artists.\n",
    "\n",
    "1.  **Create the Class:** Define a class `GNNLinkPredictor` that inherits from `torch.nn.Module`.\n",
    "2.  **Define Layers in `__init__`:** The constructor should accept `num_nodes`, `embedding_dim`, `hidden_channels`, and `out_channels` as arguments.\n",
    "    * **Embedding Layer:** Create an `nn.Embedding(num_nodes, embedding_dim)` layer. This will store the learnable feature vector for every node in the graph.\n",
    "    * **Convolution Layers:** Define two `SAGEConv` layers. The first layer's `in_channels` must match your `embedding_dim`.\n",
    "3.  **Implement the Encoder:** Create an `encode` method that takes node indices (`x`) and the message-passing edges (`edge_index`) as input.\n",
    "    * First, pass the node indices `x` through your `self.embedding` layer to get the dense node features.\n",
    "    * Then, process these features through the two `SAGEConv` layers, using a ReLU activation function in between.\n",
    "4.  **Implement the Decoder:** Create a `decode` method that takes the final node embeddings (`z`) and a set of query edges (`edge_label_index`) as input.\n",
    "    * Use the `edge_label_index` to select the embeddings for the source and destination nodes of each edge.\n",
    "    * Calculate the dot product between the source and destination node embeddings for each edge. This dot product will be our link prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNLinkPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_nodes, embedding_dim, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeding=nn.Embedding(num_nodes, embedding_dim)\n",
    "        \n",
    "        self.conv1=SAGEConv(embedding_dim,hidden_channels)\n",
    "        self.conv2=SAGEConv(hidden_channels,out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def encoder(self,x,edge_index):\n",
    "        x=self.embeding(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decoder(self,z,edge_index_label):\n",
    "        source = z[edge_index_label[0]]\n",
    "        destination = z[edge_index_label[1]]\n",
    "\n",
    "        product = (source * destination).sum(dim=1)\n",
    "\n",
    "        return product\n",
    "\n",
    "    def forward(self,x, edge_index,edge_label_index):\n",
    "        z=self.encoder(x,edge_index)\n",
    "        return self.decoder(z,edge_label_index)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5: Training the Model (Est. 60 mins)**\n",
    "\n",
    "With the model and data ready, you will write a standard PyTorch training loop to optimize the model's parameters.\n",
    "\n",
    "1.  **Initialize:** Instantiate your `GNNLinkPredictor` model, an `Adam` optimizer, and the `BCEWithLogitsLoss` loss function, which is ideal for binary classification tasks like link prediction.\n",
    "2.  **Define the `train` function:** This function will perform one full training step. It should accept the `train_data` object as an argument.\n",
    "3.  **Inside the function:**\n",
    "    * Get the node indices (`x`), message-passing edges (`edge_index`), and positive supervision links (`pos_edge_label_index`) from the `train_data` object.\n",
    "    * **Negative Sampling:** For every positive link, we need a negative one. Use the `torch_geometric.utils.negative_sampling` function to generate a tensor of non-existent edges. Set `num_neg_samples` to be equal to the number of positive edges.\n",
    "    * Combine the positive and negative supervision links into a single `edge_label_index` tensor.\n",
    "    * Pass the node indices, message-passing edges, and combined supervision links to the model to get predictions.\n",
    "    * Create the ground-truth `edge_label` tensor: a tensor of 1s for the positive links and 0s for the negative links.\n",
    "    * Calculate the loss, backpropagate, and update the model weights with `optimizer.step()`.\n",
    "4.  **Run the Loop:** Call your `train(train_data)` function repeatedly in a `for` loop for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GNNLinkPredictor(len(unique_id),100,25,1)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (train_data):\n",
    "    edge_index = train_data.edge_index\n",
    "    pos_edge_label_index=train_data.pos_edge_label_index\n",
    "    dimention=len(pos_edge_label_index[1])\n",
    "    neg_sampling= negative_sampling(edge_index=edge_index,num_neg_samples=dimention)\n",
    "    edge_label_index=  torch.cat([pos_edge_label_index, neg_sampling], dim=1)\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    edge_label=torch.cat([torch.ones(dimention),torch.zeros(dimention)])\n",
    "    pred = model(train_data.x, train_data.edge_index, edge_label_index)\n",
    "\n",
    "\n",
    "\n",
    "    loss=F.binary_cross_entropy_with_logits(pred,edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Found indices in 'edge_index' that are larger than 17643 (got 19523). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 17644) in your node feature matrix and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[101], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m edge_label\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mones(dimention),torch\u001b[38;5;241m.\u001b[39mzeros(dimention)])\n\u001b[1;32m---> 11\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_label_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(pred,edge_label)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[87], line 31\u001b[0m, in \u001b[0;36mGNNLinkPredictor.forward\u001b[1;34m(self, x, edge_index, edge_label_index)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x, edge_index,edge_label_index):\n\u001b[1;32m---> 31\u001b[0m     z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z,edge_label_index)\n",
      "Cell \u001b[1;32mIn[87], line 16\u001b[0m, in \u001b[0;36mGNNLinkPredictor.encoder\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencoder\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,edge_index):\n\u001b[0;32m     14\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeding(x)\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[0;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_y4sdud4l.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    168\u001b[0m         out,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_y4sdud4l.py:83\u001b[0m, in \u001b[0;36mcollect\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[1;32m---> 83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:282\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound negative indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mIndexError\u001b[0m: Found indices in 'edge_index' that are larger than 17643 (got 19523). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 17644) in your node feature matrix and try again."
     ]
    }
   ],
   "source": [
    "loss=train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6: Evaluation (Est. 20 mins)**\n",
    "\n",
    "Finally, evaluate your trained model's ability to distinguish between true and false links on the unseen test dataset. We will use the **AUC (Area Under the ROC Curve)** metric.\n",
    "\n",
    "1.  **Define the `test` function:** Create a function that accepts a data object (e.g., `val_data` or `test_data`). It should be decorated with `@torch.no_grad()` to disable gradient calculations.\n",
    "2.  **Inside the function:**\n",
    "    * Set the model to evaluation mode with `model.eval()`.\n",
    "    * Get the necessary tensors from the input `data` object: `x`, `edge_index` (for encoding), `pos_edge_label_index`, and `neg_edge_label_index` (for decoding).\n",
    "    * First, generate the final node embeddings by calling `model.encode(x, edge_index)`.\n",
    "    * Then, get the prediction scores for the test links by calling `model.decode(z, edge_label_index)`.\n",
    "    * Create the ground-truth labels (1s and 0s) for the positive and negative test links.\n",
    "    * Use `sklearn.metrics.roc_auc_score` to compute the AUC score between your predictions and the true labels.\n",
    "3.  **Run Evaluation:** Call your `test` function with the `test_data` object to get the final performance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Final Deliverables\n",
    "\n",
    "* A Python script (`.ipynb`) containing the full implementation of all steps.\n",
    "\n",
    "* A brief summary (in comments or a markdown cell) reporting your final test AUC score and a short reflection:\n",
    "\n",
    "    * Did the model perform better than random guessing?\n",
    "\n",
    "    * What is one way you could potentially improve the model if you had more time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_project_Recomended_systeme",
   "language": "python",
   "name": "mini_project_recomended_systeme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
